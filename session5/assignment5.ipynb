{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realpranav93/EVA-projects/blob/master/session5/assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "06a77540-6f5b-4454-a80c-68b48548eed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "1cbb2d06-6714-4511-9ba8-3649d58b093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "#@title\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa3fc5a32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "4ae7c32b-f279-4a6f-e6fe-bffc72cbeda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title\n",
        "y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "ca51b158-08c8-4f43-e0a2-72fba3115262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#@title\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYOp0EHERgE",
        "colab_type": "text"
      },
      "source": [
        "Adding a Prepocess Step for Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8mPtXmdEQcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "image_norm = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "image_norm.fit(X_train)\n",
        "train_iterator = image_norm.flow(X_train,Y_train,batch_size = 64)\n",
        "test_iterator = image_norm.flow(X_test,Y_test,batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjMPpEaWhtCC",
        "colab_type": "text"
      },
      "source": [
        "FOURTH ITERATION FROM ASSIGNMENT4 WITH CHANGES - version2\n",
        "---\n",
        "1. Image Normalization\n",
        "2. L2 regularization\n",
        "3. Activation after BN\n",
        "4. Saving the best model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxLUA_RK6Ez8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3998
        },
        "outputId": "eaabcc2f-e2f9-40de-af86-22976240602b"
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Convolution2D(10, 3, 3, input_shape=(28,28,1),use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #26\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #24\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #22\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.15))\n",
        "\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "model2.add(Convolution2D(10,1,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #11\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #9\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #7\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(10,1,use_bias = False,kernel_regularizer=regularizers.l2(0.0001)))#7\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(10,7,kernel_regularizer=regularizers.l2(0.0001))) #1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Activation('softmax'))\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model_path = 'model.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
        "callbacks = [\n",
        "    LearningRateScheduler(scheduler, verbose=1),\n",
        "    ModelCheckpoint(model_path,\n",
        "        monitor='val_acc', \n",
        "        save_best_only=True, \n",
        "        mode='max',\n",
        "        verbose=0)\n",
        "]\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model2.fit_generator(train_iterator,epochs=40, verbose=1,steps_per_epoch=len(train_iterator),validation_data=test_iterator,validation_steps = len(test_iterator), callbacks=callbacks)\n",
        "#score = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "#print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), input_shape=(28, 28, 1..., use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 18)        1620      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 18)        72        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 18)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 18)        2916      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 18)        72        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 18)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 22, 22, 18)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 18)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 10)        180       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 18)          1620      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 18)          72        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 9, 9, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 18)          2916      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 18)          72        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 7, 7, 18)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          180       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,840\n",
            "Trainable params: 14,636\n",
            "Non-trainable params: 204\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.1504 - acc: 0.9582 - val_loss: 0.0795 - val_acc: 0.9788\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0683 - acc: 0.9841 - val_loss: 0.0601 - val_acc: 0.9862\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0583 - acc: 0.9876 - val_loss: 0.0514 - val_acc: 0.9889\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0510 - acc: 0.9897 - val_loss: 0.0656 - val_acc: 0.9857\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "938/938 [==============================] - 14s 14ms/step - loss: 0.0471 - acc: 0.9907 - val_loss: 0.0432 - val_acc: 0.9922\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.0433 - acc: 0.9916 - val_loss: 0.0502 - val_acc: 0.9897\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0398 - acc: 0.9929 - val_loss: 0.0448 - val_acc: 0.9913\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0385 - acc: 0.9932 - val_loss: 0.0465 - val_acc: 0.9920\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0362 - acc: 0.9938 - val_loss: 0.0422 - val_acc: 0.9927\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0334 - acc: 0.9949 - val_loss: 0.0386 - val_acc: 0.9929\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0314 - acc: 0.9949 - val_loss: 0.0442 - val_acc: 0.9913\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0310 - acc: 0.9950 - val_loss: 0.0427 - val_acc: 0.9914\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0293 - acc: 0.9955 - val_loss: 0.0371 - val_acc: 0.9930\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0283 - acc: 0.9959 - val_loss: 0.0412 - val_acc: 0.9920\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0267 - acc: 0.9963 - val_loss: 0.0349 - val_acc: 0.9934\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0260 - acc: 0.9963 - val_loss: 0.0406 - val_acc: 0.9922\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0250 - acc: 0.9967 - val_loss: 0.0384 - val_acc: 0.9928\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0243 - acc: 0.9971 - val_loss: 0.0387 - val_acc: 0.9929\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0235 - acc: 0.9968 - val_loss: 0.0399 - val_acc: 0.9926\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0220 - acc: 0.9973 - val_loss: 0.0416 - val_acc: 0.9917\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0220 - acc: 0.9970 - val_loss: 0.0364 - val_acc: 0.9936\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0206 - acc: 0.9976 - val_loss: 0.0377 - val_acc: 0.9929\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0210 - acc: 0.9973 - val_loss: 0.0400 - val_acc: 0.9925\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0204 - acc: 0.9975 - val_loss: 0.0340 - val_acc: 0.9941\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0199 - acc: 0.9976 - val_loss: 0.0349 - val_acc: 0.9938\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0186 - acc: 0.9982 - val_loss: 0.0348 - val_acc: 0.9933\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0189 - acc: 0.9978 - val_loss: 0.0350 - val_acc: 0.9934\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0181 - acc: 0.9980 - val_loss: 0.0358 - val_acc: 0.9930\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0177 - acc: 0.9982 - val_loss: 0.0353 - val_acc: 0.9937\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0174 - acc: 0.9984 - val_loss: 0.0395 - val_acc: 0.9923\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0173 - acc: 0.9981 - val_loss: 0.0341 - val_acc: 0.9939\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0162 - acc: 0.9987 - val_loss: 0.0361 - val_acc: 0.9931\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0161 - acc: 0.9986 - val_loss: 0.0381 - val_acc: 0.9927\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0158 - acc: 0.9984 - val_loss: 0.0335 - val_acc: 0.9936\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0154 - acc: 0.9986 - val_loss: 0.0351 - val_acc: 0.9936\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0153 - acc: 0.9986 - val_loss: 0.0371 - val_acc: 0.9925\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0150 - acc: 0.9986 - val_loss: 0.0360 - val_acc: 0.9920\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0148 - acc: 0.9988 - val_loss: 0.0341 - val_acc: 0.9934\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0143 - acc: 0.9989 - val_loss: 0.0344 - val_acc: 0.9940\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0145 - acc: 0.9988 - val_loss: 0.0361 - val_acc: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3dc518c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCN2-qGz7nH",
        "colab_type": "text"
      },
      "source": [
        "Importing the best fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQnJhtRCW_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model \n",
        "final_model = load_model('model.24-0.03.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_N_cuLHz_gr",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv9pzET_jtvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55663e80-298e-4220-afac-31bffc976dbc"
      },
      "source": [
        "score = final_model.evaluate_generator(test_iterator,steps=len(test_iterator))\n",
        "print(score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0336482815310359, 0.9943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkQq3pjO0O1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2ff16606-feb3-4065-8c67-6f249cc9a3ed"
      },
      "source": [
        "predicted = final_model.predict_generator(test_iterator,steps=len(test_iterator),verbose=1) \n",
        "predicted"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3875279e-08, 1.5184404e-06, 4.7798012e-04, ..., 3.5637186e-06,\n",
              "        2.2748040e-02, 9.5216352e-01],\n",
              "       [2.8184365e-11, 1.4259697e-12, 1.3260355e-08, ..., 8.2674126e-15,\n",
              "        9.9999785e-01, 9.9589337e-10],\n",
              "       [9.9994469e-01, 1.4090588e-06, 3.6844114e-05, ..., 1.2973686e-07,\n",
              "        1.2071213e-05, 2.0506297e-08],\n",
              "       ...,\n",
              "       [9.4811811e-11, 9.3606971e-08, 2.7648948e-09, ..., 1.5396679e-05,\n",
              "        2.1029898e-07, 9.9972659e-01],\n",
              "       [1.9223856e-09, 2.1607756e-11, 1.3151443e-05, ..., 6.0330439e-12,\n",
              "        9.9998605e-01, 2.4453120e-10],\n",
              "       [1.3134243e-11, 3.8881533e-11, 1.7184590e-13, ..., 4.2043907e-12,\n",
              "        2.9494824e-08, 1.4286767e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVxzLdMHkAub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "9284d052-5814-4669-8954-80309497d427"
      },
      "source": [
        "Y_test"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 1., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Az-pw8LSkKGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "887168f4-3410-45c0-f679-efbb507a5043"
      },
      "source": [
        "actual_predicted"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ha8R02X7YK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "57028fcd-4d34-4acb-b879-5f5b9ccb9913"
      },
      "source": [
        "actual_predicted = np.rint(predicted)\n",
        "Predicted_label = np.where(actual_predicted==1)[1]\n",
        "Y_test_label = np.where(Y_test==1)[1]\n",
        "index = Predicted_label[Predicted_label != Y_test_label[0:9997]][0:25]\n",
        "index"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([9, 8, 0, 3, 9, 3, 1, 8, 0, 1, 7, 0, 1, 2, 5, 7, 8, 4, 1, 6, 2, 2,\n",
              "       8, 3, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d67WrWPplWVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# plots images with labels within jupyter notebook\n",
        "def plots(ims, figsize=(12,6), rows=2, interp=False,titles = None):\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        sp.axis('Off')\n",
        "        plt.imshow(ims[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-7-prodSo9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_original, y_train_original), (X_test_orginal, y_test_orginal) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7GPswHGEGBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "60887c94-4535-4bf6-e42c-fd3d05be05ee"
      },
      "source": [
        "plots(ims = X_test_orginal[index],titles=Predicted_label[index])"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsIAAAEOCAYAAACD0HGLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 25 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}