{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assignment5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/realpranav93/EVA-projects/blob/master/session5/assignment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3m3w1Cw49Zkt",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# https://keras.io/\n",
        "!pip install -q keras\n",
        "import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eso6UHE080D4",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Add\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "\n",
        "from keras.datasets import mnist"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eRM0QWN83PV",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "06a77540-6f5b-4454-a80c-68b48548eed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#@title\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4a4Be72j8-ZC",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "1cbb2d06-6714-4511-9ba8-3649d58b093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "#@title\n",
        "print (X_train.shape)\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.imshow(X_train[0])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa3fc5a32b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkmprriw9AnZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28,1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28,1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2m4YS4E9CRh",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mn0vAYD9DvB",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "4ae7c32b-f279-4a6f-e6fe-bffc72cbeda0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#@title\n",
        "y_train[:10]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG8JiXR39FHC",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title\n",
        "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
        "Y_train = np_utils.to_categorical(y_train, 10)\n",
        "Y_test = np_utils.to_categorical(y_test, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYlFRvKS9HMB",
        "colab_type": "code",
        "cellView": "both",
        "outputId": "ca51b158-08c8-4f43-e0a2-72fba3115262",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#@title\n",
        "Y_train[:10]\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rqYOp0EHERgE",
        "colab_type": "text"
      },
      "source": [
        "Adding a Prepocess Step for Image normalization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8mPtXmdEQcu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "image_norm = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "image_norm.fit(X_train)\n",
        "train_iterator = image_norm.flow(X_train,Y_train,batch_size = 64)\n",
        "test_iterator = image_norm.flow(X_test,Y_test,batch_size = 64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjMPpEaWhtCC",
        "colab_type": "text"
      },
      "source": [
        "FOURTH ITERATION FROM ASSIGNMENT4 WITH CHANGES - version2\n",
        "---\n",
        "1. Image Normalization\n",
        "2. L2 regularization\n",
        "3. Activation after BN\n",
        "4. Saving the best model\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxLUA_RK6Ez8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3998
        },
        "outputId": "eaabcc2f-e2f9-40de-af86-22976240602b"
      },
      "source": [
        "from keras.layers import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import LearningRateScheduler,ModelCheckpoint\n",
        "from keras import regularizers\n",
        "\n",
        "\n",
        "model2 = Sequential()\n",
        "\n",
        "model2.add(Convolution2D(10, 3, 3, input_shape=(28,28,1),use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #26\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #24\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #22\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.15))\n",
        "\n",
        "model2.add(MaxPooling2D(pool_size=(2, 2))) #11\n",
        "model2.add(Convolution2D(10,1,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #11\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #9\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(18, 3,use_bias = False,kernel_regularizer=regularizers.l2(0.0001))) #7\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Dropout(0.15))\n",
        "\n",
        "\n",
        "model2.add(Convolution2D(10,1,use_bias = False,kernel_regularizer=regularizers.l2(0.0001)))#7\n",
        "model2.add(BatchNormalization())\n",
        "model2.add(Activation('relu'))\n",
        "model2.add(Convolution2D(10,7,kernel_regularizer=regularizers.l2(0.0001))) #1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model2.add(Flatten())\n",
        "model2.add(Activation('softmax'))\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "  return round(0.003 * 1/(1 + 0.319 * epoch), 10)\n",
        "\n",
        "model_path = 'model.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
        "callbacks = [\n",
        "    LearningRateScheduler(scheduler, verbose=1),\n",
        "    ModelCheckpoint(model_path,\n",
        "        monitor='val_acc', \n",
        "        save_best_only=True, \n",
        "        mode='max',\n",
        "        verbose=0)\n",
        "]\n",
        "\n",
        "model2.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.003), metrics=['accuracy'])\n",
        "\n",
        "\n",
        "model2.fit_generator(train_iterator,epochs=40, verbose=1,steps_per_epoch=len(train_iterator),validation_data=test_iterator,validation_steps = len(test_iterator), callbacks=callbacks)\n",
        "#score = model2.evaluate(X_test, Y_test, verbose=0)\n",
        "#print(score)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(10, (3, 3), input_shape=(28, 28, 1..., use_bias=False, kernel_regularizer=<keras.reg...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 26, 26, 10)        90        \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 26, 26, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 26, 26, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 24, 24, 18)        1620      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 24, 24, 18)        72        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 24, 24, 18)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 22, 22, 18)        2916      \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 22, 22, 18)        72        \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 22, 22, 18)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 22, 22, 18)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 11, 11, 18)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 11, 11, 10)        180       \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 11, 11, 10)        40        \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 11, 11, 10)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 9, 9, 18)          1620      \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 9, 9, 18)          72        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 9, 9, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 7, 7, 18)          2916      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 7, 7, 18)          72        \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 7, 7, 18)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 7, 7, 18)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 7, 7, 10)          180       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 10)          4910      \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 10)                0         \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 14,840\n",
            "Trainable params: 14,636\n",
            "Non-trainable params: 204\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/40\n",
            "\n",
            "Epoch 00001: LearningRateScheduler setting learning rate to 0.003.\n",
            "938/938 [==============================] - 17s 18ms/step - loss: 0.1504 - acc: 0.9582 - val_loss: 0.0795 - val_acc: 0.9788\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 00002: LearningRateScheduler setting learning rate to 0.0022744503.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0683 - acc: 0.9841 - val_loss: 0.0601 - val_acc: 0.9862\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 00003: LearningRateScheduler setting learning rate to 0.0018315018.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0583 - acc: 0.9876 - val_loss: 0.0514 - val_acc: 0.9889\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 00004: LearningRateScheduler setting learning rate to 0.0015329586.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0510 - acc: 0.9897 - val_loss: 0.0656 - val_acc: 0.9857\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 00005: LearningRateScheduler setting learning rate to 0.0013181019.\n",
            "938/938 [==============================] - 14s 14ms/step - loss: 0.0471 - acc: 0.9907 - val_loss: 0.0432 - val_acc: 0.9922\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 00006: LearningRateScheduler setting learning rate to 0.0011560694.\n",
            "938/938 [==============================] - 14s 15ms/step - loss: 0.0433 - acc: 0.9916 - val_loss: 0.0502 - val_acc: 0.9897\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 00007: LearningRateScheduler setting learning rate to 0.0010295127.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0398 - acc: 0.9929 - val_loss: 0.0448 - val_acc: 0.9913\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 00008: LearningRateScheduler setting learning rate to 0.0009279307.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0385 - acc: 0.9932 - val_loss: 0.0465 - val_acc: 0.9920\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 00009: LearningRateScheduler setting learning rate to 0.0008445946.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0362 - acc: 0.9938 - val_loss: 0.0422 - val_acc: 0.9927\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 00010: LearningRateScheduler setting learning rate to 0.0007749935.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0334 - acc: 0.9949 - val_loss: 0.0386 - val_acc: 0.9929\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 00011: LearningRateScheduler setting learning rate to 0.0007159905.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0314 - acc: 0.9949 - val_loss: 0.0442 - val_acc: 0.9913\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 00012: LearningRateScheduler setting learning rate to 0.000665336.\n",
            "938/938 [==============================] - 13s 13ms/step - loss: 0.0310 - acc: 0.9950 - val_loss: 0.0427 - val_acc: 0.9914\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 00013: LearningRateScheduler setting learning rate to 0.0006213753.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0293 - acc: 0.9955 - val_loss: 0.0371 - val_acc: 0.9930\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 00014: LearningRateScheduler setting learning rate to 0.0005828638.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0283 - acc: 0.9959 - val_loss: 0.0412 - val_acc: 0.9920\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 00015: LearningRateScheduler setting learning rate to 0.0005488474.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0267 - acc: 0.9963 - val_loss: 0.0349 - val_acc: 0.9934\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 00016: LearningRateScheduler setting learning rate to 0.0005185825.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0260 - acc: 0.9963 - val_loss: 0.0406 - val_acc: 0.9922\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 00017: LearningRateScheduler setting learning rate to 0.000491481.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0250 - acc: 0.9967 - val_loss: 0.0384 - val_acc: 0.9928\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 00018: LearningRateScheduler setting learning rate to 0.0004670715.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0243 - acc: 0.9971 - val_loss: 0.0387 - val_acc: 0.9929\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 00019: LearningRateScheduler setting learning rate to 0.0004449718.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0235 - acc: 0.9968 - val_loss: 0.0399 - val_acc: 0.9926\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 00020: LearningRateScheduler setting learning rate to 0.000424869.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0220 - acc: 0.9973 - val_loss: 0.0416 - val_acc: 0.9917\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 00021: LearningRateScheduler setting learning rate to 0.0004065041.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0220 - acc: 0.9970 - val_loss: 0.0364 - val_acc: 0.9936\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 00022: LearningRateScheduler setting learning rate to 0.000389661.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0206 - acc: 0.9976 - val_loss: 0.0377 - val_acc: 0.9929\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 00023: LearningRateScheduler setting learning rate to 0.0003741581.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0210 - acc: 0.9973 - val_loss: 0.0400 - val_acc: 0.9925\n",
            "Epoch 24/40\n",
            "\n",
            "Epoch 00024: LearningRateScheduler setting learning rate to 0.0003598417.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0204 - acc: 0.9975 - val_loss: 0.0340 - val_acc: 0.9941\n",
            "Epoch 25/40\n",
            "\n",
            "Epoch 00025: LearningRateScheduler setting learning rate to 0.0003465804.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0199 - acc: 0.9976 - val_loss: 0.0349 - val_acc: 0.9938\n",
            "Epoch 26/40\n",
            "\n",
            "Epoch 00026: LearningRateScheduler setting learning rate to 0.0003342618.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0186 - acc: 0.9982 - val_loss: 0.0348 - val_acc: 0.9933\n",
            "Epoch 27/40\n",
            "\n",
            "Epoch 00027: LearningRateScheduler setting learning rate to 0.0003227889.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0189 - acc: 0.9978 - val_loss: 0.0350 - val_acc: 0.9934\n",
            "Epoch 28/40\n",
            "\n",
            "Epoch 00028: LearningRateScheduler setting learning rate to 0.0003120774.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0181 - acc: 0.9980 - val_loss: 0.0358 - val_acc: 0.9930\n",
            "Epoch 29/40\n",
            "\n",
            "Epoch 00029: LearningRateScheduler setting learning rate to 0.000302054.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0177 - acc: 0.9982 - val_loss: 0.0353 - val_acc: 0.9937\n",
            "Epoch 30/40\n",
            "\n",
            "Epoch 00030: LearningRateScheduler setting learning rate to 0.0002926544.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0174 - acc: 0.9984 - val_loss: 0.0395 - val_acc: 0.9923\n",
            "Epoch 31/40\n",
            "\n",
            "Epoch 00031: LearningRateScheduler setting learning rate to 0.0002838221.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0173 - acc: 0.9981 - val_loss: 0.0341 - val_acc: 0.9939\n",
            "Epoch 32/40\n",
            "\n",
            "Epoch 00032: LearningRateScheduler setting learning rate to 0.0002755074.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0162 - acc: 0.9987 - val_loss: 0.0361 - val_acc: 0.9931\n",
            "Epoch 33/40\n",
            "\n",
            "Epoch 00033: LearningRateScheduler setting learning rate to 0.000267666.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0161 - acc: 0.9986 - val_loss: 0.0381 - val_acc: 0.9927\n",
            "Epoch 34/40\n",
            "\n",
            "Epoch 00034: LearningRateScheduler setting learning rate to 0.0002602585.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0158 - acc: 0.9984 - val_loss: 0.0335 - val_acc: 0.9936\n",
            "Epoch 35/40\n",
            "\n",
            "Epoch 00035: LearningRateScheduler setting learning rate to 0.00025325.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0154 - acc: 0.9986 - val_loss: 0.0351 - val_acc: 0.9936\n",
            "Epoch 36/40\n",
            "\n",
            "Epoch 00036: LearningRateScheduler setting learning rate to 0.0002466091.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0153 - acc: 0.9986 - val_loss: 0.0371 - val_acc: 0.9925\n",
            "Epoch 37/40\n",
            "\n",
            "Epoch 00037: LearningRateScheduler setting learning rate to 0.0002403076.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0150 - acc: 0.9986 - val_loss: 0.0360 - val_acc: 0.9920\n",
            "Epoch 38/40\n",
            "\n",
            "Epoch 00038: LearningRateScheduler setting learning rate to 0.0002343201.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0148 - acc: 0.9988 - val_loss: 0.0341 - val_acc: 0.9934\n",
            "Epoch 39/40\n",
            "\n",
            "Epoch 00039: LearningRateScheduler setting learning rate to 0.0002286237.\n",
            "938/938 [==============================] - 13s 14ms/step - loss: 0.0143 - acc: 0.9989 - val_loss: 0.0344 - val_acc: 0.9940\n",
            "Epoch 40/40\n",
            "\n",
            "Epoch 00040: LearningRateScheduler setting learning rate to 0.0002231977.\n",
            "938/938 [==============================] - 12s 13ms/step - loss: 0.0145 - acc: 0.9988 - val_loss: 0.0361 - val_acc: 0.9934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa3dc518c88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUCN2-qGz7nH",
        "colab_type": "text"
      },
      "source": [
        "Importing the best fit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIQnJhtRCW_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model \n",
        "final_model = load_model('model.24-0.03.hdf5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_N_cuLHz_gr",
        "colab_type": "text"
      },
      "source": [
        "Evaluating the model score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv9pzET_jtvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "55663e80-298e-4220-afac-31bffc976dbc"
      },
      "source": [
        "score = final_model.evaluate_generator(test_iterator,steps=len(test_iterator))\n",
        "print(score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0336482815310359, 0.9943]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkQq3pjO0O1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "2ff16606-feb3-4065-8c67-6f249cc9a3ed"
      },
      "source": [
        "predicted = final_model.predict_generator(test_iterator,steps=len(test_iterator),verbose=1) \n",
        "predicted"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 0s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.3875279e-08, 1.5184404e-06, 4.7798012e-04, ..., 3.5637186e-06,\n",
              "        2.2748040e-02, 9.5216352e-01],\n",
              "       [2.8184365e-11, 1.4259697e-12, 1.3260355e-08, ..., 8.2674126e-15,\n",
              "        9.9999785e-01, 9.9589337e-10],\n",
              "       [9.9994469e-01, 1.4090588e-06, 3.6844114e-05, ..., 1.2973686e-07,\n",
              "        1.2071213e-05, 2.0506297e-08],\n",
              "       ...,\n",
              "       [9.4811811e-11, 9.3606971e-08, 2.7648948e-09, ..., 1.5396679e-05,\n",
              "        2.1029898e-07, 9.9972659e-01],\n",
              "       [1.9223856e-09, 2.1607756e-11, 1.3151443e-05, ..., 6.0330439e-12,\n",
              "        9.9998605e-01, 2.4453120e-10],\n",
              "       [1.3134243e-11, 3.8881533e-11, 1.7184590e-13, ..., 4.2043907e-12,\n",
              "        2.9494824e-08, 1.4286767e-06]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W2ha8R02X7YK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "actual_predicted = np.rint(predicted)\n",
        "incorrect_index = np.nonzero(actual_predicted != Y_test)[0][0:24]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d67WrWPplWVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# plots images with labels within jupyter notebook\n",
        "def plots(ims, figsize=(12,6), rows=2, interp=False,titles = None):\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=16)\n",
        "        sp.axis('Off')\n",
        "        plt.imshow(ims[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-7-prodSo9U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train_original, y_train_original), (X_test_orginal, y_test_orginal) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7GPswHGEGBF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 291
        },
        "outputId": "f096929b-0b79-4c69-cb6e-855807a51ff3"
      },
      "source": [
        "plots(ims = X_test_orginal[incorrect_index],titles=y_test_orginal[incorrect_index])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAESCAYAAAAc8whoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x432 with 24 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}